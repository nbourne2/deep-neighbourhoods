{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "# Warning used to notify implicit data conversions happening in the code.\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "from rasterio import plot\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals.joblib import parallel_backend\n",
    "\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point to the folder with the input data\n",
    "DATA_PATH = '/home/io/ASTROSAT/code/urban_extraction'\n",
    "\n",
    "\n",
    "# load training datasets\n",
    "glob_path = glob.glob(os.path.join(DATA_PATH, 'training_data', '*'))\n",
    "shapefiles = [f for f in glob_path if f.endswith('.shp')]\n",
    "\n",
    "def load_raster(input_file):\n",
    "    with rasterio.open(input_file) as src:\n",
    "        band_rgb = src.read()\n",
    "        transform = src.transform\n",
    "        shape = src.shape\n",
    "        profile = src.profile\n",
    "\n",
    "        return {'band_rgb': band_rgb, 'transform': transform, 'shape': shape, 'profile': profile}\n",
    "\n",
    "\n",
    "\n",
    "def rasterize(vector_Data):\n",
    "    raster = load_raster(os.path.join(\n",
    "        DATA_PATH, 'input', 'Sentinel-2_RGB.tiff'))\n",
    "\n",
    "    labeled_pixels = np.zeros((raster['shape'][0], raster['shape'][1]))\n",
    "    for i, shp in enumerate(vector_Data):\n",
    "        label = i+1\n",
    "        df = gpd.read_file(shp)\n",
    "        geom = df['geometry']\n",
    "        vectors_rasterized = features.rasterize(geom,\n",
    "                                                out_shape=raster['shape'],\n",
    "                                                transform=raster['transform'],\n",
    "                                                all_touched=True,\n",
    "                                                fill=0, default_value=label)\n",
    "        labeled_pixels += vectors_rasterized\n",
    "\n",
    "    return labeled_pixels\n",
    "\n",
    "\n",
    "def training_samples():\n",
    "    raster = load_raster(os.path.join(\n",
    "        DATA_PATH, 'input', 'Sentinel-2_RGB.tiff'))\n",
    "    # convert shape of raster from bands:rows:cols to rows:cols:bands\n",
    "    raster_img = np.rollaxis(raster['band_rgb'], 0, 3)\n",
    "    # produce rasterized data\n",
    "    labeled_pixels = rasterize(shapefiles)\n",
    "\n",
    "    roi_int = labeled_pixels.astype(int)\n",
    "    # X is the matrix containing our features\n",
    "    X = raster_img[roi_int > 0]\n",
    "    # y contains the values of our training data\n",
    "    y = labeled_pixels[labeled_pixels > 0]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def split(X, y):\n",
    "    #X, y = training_samples()\n",
    "    split_test_data = 0.30\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=split_test_data, stratify=y)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'svm__gamma': 0.019306977288832496, 'svm__C': 51.7947467923121}\n",
      "Classification accuracy: 0.9426256077795786\n",
      "Best parameters: {'svm__gamma': 0.019306977288832496, 'svm__C': 51.7947467923121}\n",
      "Classification accuracy: 0.9426256077795786\n",
      "Best parameters: {'svm__gamma': 0.019306977288832496, 'svm__C': 51.7947467923121}\n",
      "Classification accuracy: 0.9426256077795786\n",
      "Best parameters: {'svm__gamma': 0.019306977288832496, 'svm__C': 51.7947467923121}\n",
      "Classification accuracy: 0.9426256077795786\n",
      "Best parameters: {'svm__gamma': 0.019306977288832496, 'svm__C': 51.7947467923121}\n",
      "Classification accuracy: 0.9426256077795786\n",
      "Best parameters: {'svm__gamma': 0.019306977288832496, 'svm__C': 51.7947467923121}\n",
      "Classification accuracy: 0.9426256077795786\n",
      "Best parameters: {'svm__gamma': 0.019306977288832496, 'svm__C': 51.7947467923121}\n",
      "Classification accuracy: 0.9426256077795786\n",
      "Best parameters: {'svm__gamma': 0.019306977288832496, 'svm__C': 51.7947467923121}\n",
      "Best parameters: {'svm__gamma': 0.019306977288832496, 'svm__C': 51.7947467923121}\n",
      "Classification accuracy: 0.9426256077795786\n",
      "Classification accuracy: 0.9426256077795786\n",
      "Best parameters: {'svm__gamma': 0.019306977288832496, 'svm__C': 51.7947467923121}\n",
      "Classification accuracy: 0.9426256077795786\n",
      "Best parameters: {'svm__gamma': 0.019306977288832496, 'svm__C': 51.7947467923121}\n",
      "Classification accuracy: 0.9426256077795786\n",
      "Best parameters: {'svm__gamma': 0.019306977288832496, 'svm__C': 51.7947467923121}\n",
      "Classification accuracy: 0.9426256077795786\n",
      "Confusion matrix: \n",
      " [[ 603   53   21   68]\n",
      " [   0 1048    0    1]\n",
      " [  17    0 1406    1]\n",
      " [  56    2    1 1131]]\n",
      "\n",
      "\n",
      "Classificaion report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      urban       0.89      0.81      0.85       745\n",
      "      water       0.95      1.00      0.97      1049\n",
      "      grass       0.98      0.99      0.99      1424\n",
      "bare_ground       0.94      0.95      0.95      1190\n",
      "\n",
      "avg / total       0.95      0.95      0.95      4408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def tune(X, y, search_type):\n",
    "    X, y = training_samples()\n",
    "    X_train, X_test, y_train, y_test = split(X,y)\n",
    "    \n",
    "    param_range_c = np.logspace(0, 2, 8)\n",
    "    param_range_gamma = np.logspace(-6, -1, 8)\n",
    "\n",
    "    param_grid = {'svm__C': param_range_c,\n",
    "                  'svm__gamma': param_range_gamma}\n",
    "\n",
    "    pip = Pipeline([('scale', preprocessing.StandardScaler()),\n",
    "                    ('svm', SVC(kernel='rbf', class_weight='balanced'))])\n",
    "\n",
    "    if search_type == 'grid':\n",
    "        clf = GridSearchCV(estimator=pip,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=3)\n",
    "                           #n_jobs=-1)\n",
    "\n",
    "        \n",
    "        clf = clf.fit(X_train, y_train)\n",
    "\n",
    "        # print accuracy of the model\n",
    "        print('Best parameters:', clf.best_params_)\n",
    "        print('Classification accuracy', clf.best_score_)\n",
    "\n",
    "    elif search_type == 'random':\n",
    "        clf = RandomizedSearchCV(estimator=pip,\n",
    "                                 param_distributions=param_grid,\n",
    "                                 scoring='accuracy',\n",
    "                                 cv=3,\n",
    "                                 n_iter=15,\n",
    "                                 error_score='numeric')  # it supresses the warning error\n",
    "                                 #n_jobs=-1)\n",
    "\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "\n",
    "        # print accuracy of the model\n",
    "        print('Best parameters:', clf.best_params_)\n",
    "        print('Classification accuracy:', clf.best_score_)\n",
    "\n",
    "    return clf\n",
    "\n",
    "\n",
    "def predict(input_data):\n",
    "    X, y = training_samples()\n",
    "    X_train, X_test, y_train, y_test = split(X,y)\n",
    "    clf = tune(X_train, y_train, 'random')\n",
    "    y_predict = clf.predict(input_data)\n",
    "    return y_predict\n",
    "\n",
    "\n",
    "def parallel_processing():\n",
    "    raster = load_raster(os.path.join(\n",
    "        DATA_PATH, 'input', 'Sentinel-2_RGB.tiff'))\n",
    "    raster_img = np.rollaxis(raster['band_rgb'], 0, 3)\n",
    "    # split good data into chunks for parallel processing\n",
    "    cpu_n = cpu_count()\n",
    "\n",
    "    # Reshape the data so that we make predictions for the whole raster\n",
    "    new_shape = (raster_img.shape[0] *\n",
    "                 raster_img.shape[1], raster_img.shape[2])\n",
    "\n",
    "    \n",
    "    img_as_array = raster_img[:, :].reshape(new_shape)\n",
    "    image_array = np.copy(img_as_array)\n",
    "    split = np.array_split(image_array, cpu_n)\n",
    "\n",
    "    # run parallel processing of all data with SVM\n",
    "    pool = Pool(cpu_n)\n",
    "    svmLablesPredict = pool.map(predict, split)\n",
    "    # join results back from the queue and insert into full matrix\n",
    "    svmLablesPredict = np.hstack(svmLablesPredict)\n",
    "    svm_reshape = svmLablesPredict.reshape(\n",
    "        raster_img.shape[0], raster_img.shape[1])\n",
    "\n",
    "    return svm_reshape\n",
    "\n",
    "\n",
    "\n",
    "def model_accuracy():\n",
    "    svm_classified = parallel_processing()\n",
    "    labeled_pixels = rasterize(shapefiles)\n",
    "    target_names = [os.path.split(s)[1][:-4] for s in shapefiles]\n",
    "\n",
    "    for_verification = np.nonzero(labeled_pixels)\n",
    "    verification_labels = labeled_pixels[for_verification]\n",
    "    predicted_labels = svm_classified[for_verification]  # svm_reshape\n",
    "\n",
    "    print('Confusion matrix: \\n %s' %\n",
    "          confusion_matrix(verification_labels, predicted_labels))\n",
    "    print('\\n')\n",
    "\n",
    "    print('Classificaion report: \\n %s' %\n",
    "          classification_report(verification_labels, predicted_labels, target_names=target_names))\n",
    "\n",
    "    return confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "accuracy = model_accuracy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/io/ASTROSAT/code/urban_extraction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raster(input_file):\n",
    "    with rasterio.open(input_file) as src:\n",
    "        band_rgb = src.read()\n",
    "        transform = src.transform\n",
    "        shape = src.shape\n",
    "        profile = src.profile\n",
    "        \n",
    "        return {'band_rgb':band_rgb ,'transform':transform, 'shape':shape, 'profile':profile}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster, transform, shape, profile = load_raster(os.path.join(DATA_PATH,'input','Sentinel-2_RGB.tiff'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster = load_raster(os.path.join(DATA_PATH,'input','Sentinel-2_RGB.tiff'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Affine(0.0003593084656084656, 0.0, -4.521561,\n",
       "       0.0, -0.00020171566054243356, 55.955351)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raster['transform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground = gpd.read_file(os.path.join(DATA_PATH,'training_data','bare_ground.shp'))\n",
    "# water = gpd.read_file(os.path.join(DATA_PATH,'training_data','water.shp'))\n",
    "# grass = gpd.read_file(os.path.join(DATA_PATH,'training_data','grass.shp'))\n",
    "# urban = gpd.read_file(os.path.join(DATA_PATH,'training_data','urban.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_rasterized = features.rasterize([(x.geometry, 1) for i, x in ground.iterrows()],\n",
    "#                                        out_shape = shape,\n",
    "#                                        transform = transform,\n",
    "#                                        all_touched=True,\n",
    "#                                        fill=0)\n",
    "\n",
    "# water_rasterized = features.rasterize([(x.geometry, 1) for i, x in water.iterrows()],\n",
    "#                                        out_shape = shape,\n",
    "#                                        transform = transform,\n",
    "#                                        all_touched=True,\n",
    "#                                        fill=0)\n",
    "\n",
    "# grass_rasterized = features.rasterize([(x.geometry, 1) for i, x in grass.iterrows()],\n",
    "#                                        out_shape = shape,\n",
    "#                                        transform = transform,\n",
    "#                                        all_touched=True,\n",
    "#                                        fill=0)\n",
    "\n",
    "# urban_rasterized = features.rasterize([(x.geometry, 1) for i, x in urban.iterrows()],\n",
    "#                                        out_shape = shape,\n",
    "#                                        transform = transform,\n",
    "#                                        all_touched=True,\n",
    "#                                        fill=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground 1190\n",
      "water 1049\n",
      "grass 1424\n",
      "urban 745\n"
     ]
    }
   ],
   "source": [
    "# print ('ground',ground_rasterized.sum())\n",
    "# print ('water',water_rasterized.sum())\n",
    "# print ('grass',grass_rasterized.sum())\n",
    "# print ('urban',urban_rasterized.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_path = glob.glob(os.path.join(DATA_PATH,'training_data','*'))\n",
    "\n",
    "shapefiles = [f for f in glob_path if f.endswith('.shp')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_pixels = np.zeros((shape[0],shape[1]))\n",
    "\n",
    "\n",
    "for i,shp in enumerate(shapefiles):\n",
    "    label = i+1 \n",
    "    df = gpd.read_file(shp)\n",
    "    geom = df['geometry']\n",
    "    #print (i,geom)\n",
    "    vectors_rasterized = features.rasterize(geom,\n",
    "                                           out_shape = shape,\n",
    "                                           transform = transform,\n",
    "                                           all_touched=True,\n",
    "                                           default_value=label)\n",
    "    labeled_pixels += vectors_rasterized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class urban contains 745 pixels\n",
      "Class water contains 1049 pixels\n",
      "Class grass contains 1424 pixels\n",
      "Class bare_ground contains 1190 pixels\n"
     ]
    }
   ],
   "source": [
    "for i, shp in sorted(enumerate(shapefiles)):\n",
    "    i = i+1\n",
    "    shp_path = os.path.split(shp)\n",
    "    land_classes = shp_path[1][:-4]\n",
    "    print('Class {land_classes} contains {n} pixels'.format(land_classes=land_classes, n=(labeled_pixels == i).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.96      0.86      0.91       224\n",
      "        2.0       0.97      1.00      0.98       315\n",
      "        3.0       0.99      0.99      0.99       427\n",
      "        4.0       0.96      0.99      0.97       357\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1323\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/io/miniconda2/envs/geopython/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "raster_img = np.rollaxis(band_rgb,0,3)\n",
    "\n",
    "roi_int = labeled_pixels.astype(int)\n",
    "# X is the matrix containing our features\n",
    "X = raster_img[roi_int>0] \n",
    "# y contains the values of our training data\n",
    "y = labeled_pixels[labeled_pixels>0]\n",
    "\n",
    "\n",
    "#Split our dataset into training and testing. Test data will be used to make predictions\n",
    "split_test_data = 0.30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_test_data, stratify = y)\n",
    "\n",
    "#use pipeline to do all the steps automatically\n",
    "pip = Pipeline([('scale', preprocessing.StandardScaler()), \n",
    "                ('svm', SVC(kernel='rbf', C=1, gamma=10, decision_function_shape='ovo', class_weight='balanced'))])\n",
    "pip.fit(X_train, y_train)\n",
    "y_predict = pip.predict(X_test)#make prediction\n",
    "print (classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n",
      "521\n"
     ]
    }
   ],
   "source": [
    "#stratify\n",
    "print (np.sum(y_test==1))\n",
    "print (np.sum(y_train==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "505\n"
     ]
    }
   ],
   "source": [
    "print (np.sum(y_test==1))\n",
    "print (np.sum(y_train==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315\n",
      "734\n"
     ]
    }
   ],
   "source": [
    "#stratify\n",
    "print (np.sum(y_test==2))\n",
    "print (np.sum(y_train==2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n",
      "727\n"
     ]
    }
   ],
   "source": [
    "print (np.sum(y_test==2))\n",
    "print (np.sum(y_train==2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "686\n",
      "738\n"
     ]
    }
   ],
   "source": [
    "print (np.sum(y_train==3))\n",
    "print (np.sum(y_test==3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616\n",
      "574\n"
     ]
    }
   ],
   "source": [
    "print (np.sum(y_train==4))\n",
    "print (np.sum(y_test==4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped from (1143, 1890, 3) to (2160270, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/io/miniconda2/envs/geopython/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "new_shape = (raster_img.shape[0] * raster_img.shape[1], raster_img.shape[2] )\n",
    "\n",
    "img_as_array = raster_img[:,:].reshape(new_shape)\n",
    "print('Reshaped from {o} to {n}'.format(o=raster_img.shape,\n",
    "                                        n=img_as_array.shape))\n",
    "\n",
    "\n",
    "#Split our dataset into training and testing. Test data will be used to make predictions\n",
    "split_test_data = 0.30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_test_data, stratify = y)\n",
    "\n",
    "#use pipeline to do all the steps automatically\n",
    "pip = Pipeline([('scale', preprocessing.StandardScaler()), \n",
    "                ('svm', SVC(kernel='rbf', C=10, gamma=0.1, decision_function_shape='ovo', class_weight='balanced'))])\n",
    "pip.fit(X_train, y_train)\n",
    "\n",
    "# Now predict for each pixel\n",
    "class_prediction = pip.predict(img_as_array)\n",
    "\n",
    "# Reshape our classification map\n",
    "class_prediction = class_prediction.reshape(raster_img[:, :, 0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = profile\n",
    "profile.update(\n",
    "            dtype=class_prediction.dtype,\n",
    "            count=1,\n",
    "            compress='lzw', \n",
    "            nodata=0)\n",
    "\n",
    "with rasterio.open(\"/home/io/Desktop/class_prediction12.tif\", 'w', **profile) as out:\n",
    "    out.write_band(1, class_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
